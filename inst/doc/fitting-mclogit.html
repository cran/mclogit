<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>The IWLS algorithm used to fit conditional logit models</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>






<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">The IWLS algorithm used to fit conditional
logit models</h1>



<p>The package “mclogit” fits conditional logit models using a maximum
likelihood estimator. It does this by maximizing the log-likelihood
function using an <em>iterative weighted least-squares</em> (IWLS)
algorithm, which follows the algorithm used by the
<code>glm.fit()</code> function from the “stats” package of <em>R</em>
<span class="citation">(Nelder and Wedderburn 1972; McCullagh and Nelder
1989; R Core Team 2023)</span>.</p>
<p>If <span class="math inline">\(\pi_{ij}\)</span> is the probability
that individual <span class="math inline">\(i\)</span> chooses
alternative <span class="math inline">\(j\)</span> from his/her choice
set <span class="math inline">\(\mathcal{S}_i\)</span>, where</p>
<p><span class="math display">\[
\pi_{ij}=\frac{\exp(\eta_{ij})}{\sum_k{\in\mathcal{S}_i}\exp(\eta_{ik})}
\]</span></p>
<p>and if <span class="math inline">\(y_{ij}\)</span> is the dummy
variable with equals 1 if individual <span class="math inline">\(i\)</span> chooses alternative <span class="math inline">\(j\)</span> and equals 0 otherwise, the
log-likelihood function (given that the choices are identically
independent distributed given <span class="math inline">\(\pi_{ij}\)</span>) can be written as</p>
<p><span class="math display">\[
\ell=\sum_{i,j}y_{ij}\ln\pi_{ij}
    =\sum_{i,j}y_{ij}\eta_{ij}-\sum_i\ln\left(\sum_j\exp(\eta_{ij})\right)
\]</span></p>
<p>If the data are aggregated in the terms of counts such that <span class="math inline">\(n_{ij}\)</span> is the number of individuals with
the same choice set and the same choice probabilities <span class="math inline">\(\pi_{ij}\)</span> that have chosen alternative
<span class="math inline">\(j\)</span>, the log-likelihood is (given
that the choices are identically independent distributed given <span class="math inline">\(\pi_{ij}\)</span>)</p>
<p><span class="math display">\[
\ell=\sum_{i,j}n_{ij}\ln\pi_{ij}
    =\sum_{i,j}n_{ij}\eta_{ij}-\sum_in_{i+}\ln\left(\sum_j\exp(\eta_{ij})\right)
\]</span></p>
<p>where <span class="math inline">\(n_{i+}=\sum_{j\in\mathcal{S}_i}n_{ij}\)</span>.</p>
<p>If</p>
<p><span class="math display">\[
\eta_{ij} =
\alpha_1x_{1ij}+\cdots+\alpha_rx_{rij}=\boldsymbol{x}_{ij}&#39;\boldsymbol{\alpha}
\]</span></p>
<p>then the gradient of the log-likelihood with respect to the
coefficient vector <span class="math inline">\(\boldsymbol{\alpha}\)</span> is</p>
<p><span class="math display">\[
\frac{\partial\ell}{\partial\boldsymbol{\alpha}}
=
\sum_{i,j}
\frac{\partial\eta_{ij}}{\partial\boldsymbol{\alpha}}
\frac{\partial\ell}{\partial\eta_{ij}}
=
\sum_{i,j}
\boldsymbol{x}_{ij}
(n_{ij}-n_{i+}\pi_{ij})
=
\sum_{i,j}
\boldsymbol{x}_{ij}
n_{i+}
(y_{ij}-\pi_{ij})
=
\boldsymbol{X}&#39;\boldsymbol{N}(\boldsymbol{y}-\boldsymbol{\pi})
\]</span></p>
<p>and the Hessian is</p>
<p><span class="math display">\[
\frac{\partial^2\ell}{\partial\boldsymbol{\alpha}\partial\boldsymbol{\alpha}&#39;}
=
\sum_{i,j}
\frac{\partial\eta_{ij}}{\partial\boldsymbol{\alpha}}
\frac{\partial\eta_{ij}}{\partial\boldsymbol{\alpha}&#39;}
\frac{\partial\ell^2}{\partial\eta_{ij}^2}
=
-
\sum_{i,j,k}
\boldsymbol{x}_{ij}
n_{i+}
(\delta_{jk}-\pi_{ij}\pi_{ik})
\boldsymbol{x}_{ij}&#39;
=
-
\boldsymbol{X}&#39;\boldsymbol{W}\boldsymbol{X}
\]</span></p>
<p>Here <span class="math inline">\(y_{ij}=n_{ij}/n_{i+}\)</span>, while
<span class="math inline">\(\boldsymbol{N}\)</span> is a diagonal matrix
with diagonal elements <span class="math inline">\(n_{i+}\)</span>.</p>
<p>Newton-Raphson iterations then take the form</p>
<p><span class="math display">\[
\boldsymbol{\alpha}^{(s+1)}
=
\boldsymbol{\alpha}^{(s)}
-
\left(
\frac{\partial^2\ell}{\partial\boldsymbol{\alpha}\partial\boldsymbol{\alpha}&#39;}
\right)^{-1}
\frac{\partial\ell}{\partial\boldsymbol{\alpha}}
=
\boldsymbol{\alpha}^{(s)}
+
\left(
\boldsymbol{X}&#39;\boldsymbol{W}\boldsymbol{X}
\right)^{-1}
\boldsymbol{X}&#39;\boldsymbol{N}(\boldsymbol{y}-\boldsymbol{\pi})
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{\pi}\)</span> and <span class="math inline">\(\boldsymbol{W}\)</span> are evaluated at <span class="math inline">\(\boldsymbol{\alpha}=\boldsymbol{\alpha}^{(s)}\)</span>.</p>
<p>Multiplying by <span class="math inline">\(\boldsymbol{X}&#39;\boldsymbol{W}\boldsymbol{X}\)</span>
gives</p>
<p><span class="math display">\[
\boldsymbol{X}&#39;\boldsymbol{W}\boldsymbol{X}
\boldsymbol{\alpha}^{(s+1)}
=
\boldsymbol{X}&#39;\boldsymbol{W}\boldsymbol{X}
\boldsymbol{\alpha}^{(s)}
+
\boldsymbol{X}&#39;\boldsymbol{N}(\boldsymbol{y}-\boldsymbol{\pi})
=
\boldsymbol{X}&#39;\boldsymbol{W}
\left(\boldsymbol{X}\boldsymbol{\alpha}^{(s)}+\boldsymbol{W}^-\boldsymbol{N}(\boldsymbol{y}-\boldsymbol{\pi})\right)
=
\boldsymbol{X}&#39;\boldsymbol{W}\boldsymbol{y}^*
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{W}^-\)</span> is a
generalized inverse of <span class="math inline">\(\boldsymbol{W}\)</span> and <span class="math inline">\(\boldsymbol{y}^*\)</span> is a “working response
vector” with elements</p>
<p><span class="math display">\[
y_{ij}^*=\boldsymbol{x}_{ij}&#39;\boldsymbol{\alpha}^{(s)}+\frac{y_{ij}-\pi_{ij}}{\pi_{ij}}
\]</span></p>
<p>The IWLS algorithm thus involves the following steps:</p>
<ol style="list-style-type: decimal">
<li><p>Create some suitable starting values for <span class="math inline">\(\boldsymbol{\pi}\)</span>, <span class="math inline">\(\boldsymbol{W}\)</span>, and <span class="math inline">\(\boldsymbol{y}^*\)</span></p></li>
<li><p>Construct the “working dependent variable” <span class="math inline">\(\boldsymbol{y}^*\)</span></p></li>
<li><p>Solve the equation</p>
<p><span class="math display">\[
\boldsymbol{X}&#39;\boldsymbol{W}\boldsymbol{X}
\boldsymbol{\alpha}
=
\boldsymbol{X}&#39;\boldsymbol{W}\boldsymbol{y}^*
\]</span></p>
<p>for <span class="math inline">\(\boldsymbol{\alpha}\)</span>.</p></li>
<li><p>Compute updated <span class="math inline">\(\boldsymbol{\eta}\)</span>, <span class="math inline">\(\boldsymbol{\pi}\)</span>, <span class="math inline">\(\boldsymbol{W}\)</span>, and <span class="math inline">\(\boldsymbol{y}^*\)</span>.</p></li>
<li><p>Compute the updated value for the log-likelihood or the
deviance</p>
<p><span class="math display">\[
d=2\sum_{i,j}n_{ij}\ln\frac{y_{ij}}{\pi_{ij}}
\]</span></p></li>
<li><p>If the decrease of the deviance (or the increase of the
log-likelihood) is smaller than a given tolerance criterian (typically
<span class="math inline">\(\Delta d \leq 10^{-7}\)</span>) stop the
algorighm and declare it as converged. Otherwise go back to step 2 with
the updated value of <span class="math inline">\(\boldsymbol{\alpha}\)</span>.</p></li>
</ol>
<p>The starting values for the algorithm used by the <em>mclogit</em>
package are constructe as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Set</p>
<p><span class="math display">\[
\eta_{ij}^{(0)} = \ln (n_{ij}+\tfrac12)
                - \frac1{q_i}\sum_{k\in\mathcal{S}_i}\ln
(n_{ij}+\tfrac12)
\]</span></p>
<p>(where <span class="math inline">\(q_i\)</span> is the size of the
choice set <span class="math inline">\(\mathcal{S}_i\)</span>)</p></li>
<li><p>Compute the starting values of the choice probabilities <span class="math inline">\(\pi_{ij}^{(0)}\)</span> according to the equation
at the beginning of the page</p></li>
<li><p>Compute intial values of the working dependent variable according
to</p>
<p><span class="math display">\[
y_{ij}^{*(0)}
=
\eta_{ij}^{(0)}+\frac{y_{ij}-\pi_{ij}^{(0)}}{\pi_{ij}^{(0)}}
\]</span></p></li>
</ol>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-mccullagh.nelder:glm.2ed" class="csl-entry">
McCullagh, P., and J. A. Nelder. 1989. <em>Generalized Linear
Models</em>. Monographs on Statistics &amp; Applied Probability. Boca
Raton et al.: Chapman &amp; Hall/CRC.
</div>
<div id="ref-nelder.wedderburn:glm" class="csl-entry">
Nelder, J. A., and R. W. M. Wedderburn. 1972. <span>“Generalized Linear
Models.”</span> <em>Journal of the Royal Statistical Society. Series A
(General)</em> 135 (3): 370–84. <a href="https://doi.org/10.2307/2344614">https://doi.org/10.2307/2344614</a>.
</div>
<div id="ref-Rcore" class="csl-entry">
R Core Team. 2023. <em>R: A Language and Environment for Statistical
Computing</em>. Vienna, Austria: R Foundation for Statistical Computing.
<a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
